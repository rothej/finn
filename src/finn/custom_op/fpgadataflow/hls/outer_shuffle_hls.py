############################################################################
# Copyright (C) 2025, Advanced Micro Devices, Inc.
# All rights reserved.
#
# SPDX-License-Identifier: MIT
#
# @author       Shane T. Fleming <shane.fleming@amd.com>
############################################################################

import math
import numpy as np
import os
from typing import Optional

from finn.custom_op.fpgadataflow import templates
from finn.custom_op.fpgadataflow.hlsbackend import HLSBackend
from finn.custom_op.fpgadataflow.outer_shuffle import OuterShuffle
from finn.util.basic import CppBuilder
from finn.util.data_packing import npy_to_rtlsim_input, rtlsim_output_to_npy


def auto_size_simd(I_dim: int, SIMD: int) -> Optional[int]:
    """
    Return the smallest divisor d of I_dim such that d > SIMD.
    if no such divisor exists, return None.
    """
    if I_dim <= 0:
        raise ValueError("I_dim must be a positive integer")
    if SIMD < 0:
        raise ValueError("SIMD must be a non-negative integer")

    candidates = []
    limit = int(math.isqrt(I_dim))
    for a in range(1, limit + 1):
        if I_dim % a == 0:
            b = I_dim // a
            if a > SIMD:
                candidates.append(a)
            if b > SIMD:
                candidates.append(b)

    if not candidates:
        return None

    return min(candidates)


class OuterShuffle_hls(OuterShuffle, HLSBackend):
    def __init__(self, onnx_node, **kwargs):
        super().__init__(onnx_node, **kwargs)

        # check some constraints that it is a legal shuffle_hls
        last_dim = self.get_nodeattr("in_shape")[-1]
        SIMD = self.get_nodeattr("SIMD")
        if last_dim % SIMD != 0:
            # Not sure if this is the correct approach
            # we could autosize SIMD to the next biggest value that works.
            # rather than raising an error straight away
            new_simd = auto_size_simd(last_dim, SIMD)
            if new_simd is not None:
                self.set_nodeattr("SIMD", new_simd)
            else:
                raise RuntimeError("Unable to determine a new SIMD value for this transpose.")

    def get_nodeattr_types(self):
        return OuterShuffle.get_nodeattr_types(self) | HLSBackend.get_nodeattr_types(self)

    def global_includes(self):
        self.code_gen_dict["$GLOBALS$"] = [
            '#include "input_gen.hpp"',
            "#include <ap_int.h>",
            "#include <hls_vector.h>",
            "#include <hls_stream.h>",
        ]

    def defines(self, var):
        simd = self.get_nodeattr("SIMD")
        dtype = self.get_input_datatype()
        self.code_gen_dict["$DEFINES$"] = [
            f"""
            constexpr unsigned  SIMD = {simd};
            using  TE = {dtype.get_hls_datatype_str()};
            using  TV = hls::vector<TE, SIMD>;
            """
        ]

    def get_exp_cycles(self):
        out_shape = self.get_nodeattr("out_shape")
        simd = self.get_nodeattr("SIMD")
        return int(np.prod(out_shape) / simd)

    def docompute(self):
        simd = self.get_nodeattr("SIMD")
        out_shape = self.get_nodeattr("out_shape")
        out_shape[-1] = int(out_shape[-1] / simd)
        loop_coeffs = [1 if x == 1 else int(x / simd) for x in self.get_nodeattr("loop_coeffs")]
        interleaved = [int(item) for pair in zip(out_shape, loop_coeffs) for item in pair]
        self.code_gen_dict["$DOCOMPUTE$"] = [
            f"""
            hls::stream<TV>  src0;
            hls::stream<TV>  dst0;
            #pragma HLS stream variable=src0 depth=2
            #pragma HLS stream variable=dst0 depth=2

            move(in0_V, src0);
            input_gen<-1,{np.prod(out_shape)},{','.join(map(str,interleaved))}>(src0, dst0);
            move(dst0, out0_V);
            """
        ]

    def blackboxfunction(self):
        self.code_gen_dict["$BLACKBOXFUNCTION$"] = [
            f"""
            void {self.onnx_node.name} (
                hls::stream<TV> &in0_V,
                hls::stream<TV> &out0_V
            )
            """
        ]

    def pragmas(self):
        self.code_gen_dict["$PRAGMAS$"] = [
            """
            #pragma HLS interface AXIS port=in0_V
            #pragma HLS interface AXIS port=out0_V
            #pragma HLS aggregate variable=in0_V compact=bit
            #pragma HLS aggregate variable=out0_V compact=bit

            #pragma HLS interface ap_ctrl_none port=return
            #pragma HLS dataflow disable_start_propagation
            """
        ]

    def execute_node(self, context, graph):
        mode = self.get_nodeattr("exec_mode")
        node = self.onnx_node
        folded_ishape = self.get_folded_input_shape()
        export_dt = self.get_input_datatype()

        if mode == "cppsim":
            code_gen_dir = self.get_nodeattr("code_gen_dir_cppsim")
        elif mode == "rtlsim":
            code_gen_dir = self.get_nodeattr("code_gen_dir_ipgen")

        inp = context[node.input[0]]
        inp = inp.reshape(folded_ishape)
        np.save(os.path.join(code_gen_dir, "input_0.npy"), inp)

        if mode == "cppsim":
            code_gen_dir = self.get_nodeattr("code_gen_dir_cppsim")
            # execute the precompiled model
            super().exec_precompiled_singlenode_model()
            # Load output npy file
            super().npy_to_dynamic_output(context)
        elif mode == "rtlsim":
            sim = self.get_rtlsim()
            nbits = self.get_instream_width()
            rtlsim_inp = npy_to_rtlsim_input(f"{code_gen_dir}/input_0.npy", export_dt, nbits)
            super().reset_rtlsim(sim)

            io_dict = {"inputs": {"in0": rtlsim_inp}, "outputs": {"out0": []}}
            self.rtlsim_multi_io(sim, io_dict)
            super().close_rtlsim(sim)

            out = io_dict["outputs"]["out0"]
            target_bits = export_dt.bitwidth()
            packed_bits = self.get_outstream_width()
            out_npy_path = f"{code_gen_dir}/output_0.npy"
            out_shape = self.get_folded_output_shape()
            rtlsim_output_to_npy(out, out_npy_path, export_dt, out_shape, packed_bits, target_bits)

            # load and reshape output
            output = np.load(out_npy_path)
            oshape = self.get_normal_output_shape()
            output = np.asarray(
                [output],
                dtype=np.float32,
            ).reshape(*oshape)
            context[node.output[0]] = output

        else:
            raise Exception(f"Unsupported execution mode: {mode}")

    def compile_singlenode_code(self):
        """
        Builds the bash script for compilation using the CppBuilder from
        finn.util.basic and executes the script to produce the executable
        """
        code_gen_dir = self.get_nodeattr("code_gen_dir_cppsim")
        builder = CppBuilder()
        # to enable additional debug features please uncommand the next line
        # builder.append_includes("-DDEBUG")
        builder.append_includes("-I$FINN_ROOT/src/finn/qnn-data/cpp")
        builder.append_includes("-I$FINN_ROOT/deps/cnpy/")
        builder.append_includes("-I$FINN_ROOT/custom_hls")
        builder.append_includes("-I$FINN_ROOT/deps/finn-hlslib")
        if "HLS_PATH" in os.environ:
            builder.append_includes("-I{}/include".format(os.environ["HLS_PATH"]))
        if "VITIS_PATH" in os.environ:
            builder.append_includes("-I{}/include".format(os.environ["VITIS_PATH"]))
        builder.append_includes("--std=c++14")
        builder.append_includes("-O3")
        builder.append_sources(code_gen_dir + "/*.cpp")
        builder.append_sources("$FINN_ROOT/deps/cnpy/cnpy.cpp")
        builder.append_includes("-lz")
        builder.set_executable_path(code_gen_dir + "/node_model")
        builder.build(code_gen_dir)
        self.set_nodeattr("executable_path", builder.executable_path)

    def code_generation_cppsim(self, model):
        """Generates c++ code for simulation (cppsim)."""
        self.code_gen_dict["$READNPYDATA$"] = [""]
        self.code_gen_dict["$DATAOUTSTREAM$"] = [""]
        self.code_gen_dict["$STREAMDECLARATIONS$"] = [""]
        node = self.onnx_node
        path = self.get_nodeattr("code_gen_dir_cppsim")
        self.code_gen_dict["$AP_INT_MAX_W$"] = [str(self.get_ap_int_max_w())]
        self.generate_params(model, path)
        self.global_includes()
        self.defines("cppsim")
        self.pragmas()
        oshape = self.get_folded_output_shape()
        oshape_str = str(oshape).replace("(", "{").replace(")", "}")

        simd = self.get_nodeattr("SIMD")
        out_shape = self.get_nodeattr("out_shape")
        out_shape[-1] = int(out_shape[-1] / simd)
        loop_coeffs = [1 if x == 1 else int(x / simd) for x in self.get_nodeattr("loop_coeffs")]
        interleaved = [int(item) for pair in zip(out_shape, loop_coeffs) for item in pair]

        self.code_gen_dict["$DOCOMPUTE$"] = [
            f"""
            static hls::stream<TV>  in0_V;
            static hls::stream<TV>  out0_V;

            npy2vectorstream<TE, float, SIMD>("{path}/input_0.npy", in0_V);
            int stream_size = in0_V.size();

            while(out0_V.size() != stream_size) {{
                input_gen<-1,{np.prod(out_shape)},{','.join(map(str,interleaved))}>(in0_V, out0_V);
            }}

            vectorstream2npy<TE, float, SIMD>(out0_V,{oshape_str}, "{path}/output_0.npy");
            """
        ]
        self.save_as_npy()

        template = templates.docompute_template

        code_gen_dir = self.get_nodeattr("code_gen_dir_cppsim") + f"/execute_{node.op_type}.cpp"
        with open(code_gen_dir, "w") as f:
            for key in self.code_gen_dict:
                # transform list into long string separated by '\n'
                code_gen_line = "\n".join(self.code_gen_dict[key])
                template = template.replace(key, code_gen_line)
            f.write(template)
