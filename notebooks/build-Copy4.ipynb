{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5d5fc42e-1e7a-4649-bbfe-b660254925bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Serving '../workspace/jh_fpga_amr/src/py/models/vgglike_6f_6c_5re_5mp_pr0.3_quant8.onnx' at http://0.0.0.0:8081\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"400\"\n",
       "            src=\"http://localhost:8081/\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "            \n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x7fdd541d1cc0>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import finn\n",
    "from finn.util.visualization import showSrc, showInNetron\n",
    "from finn.util.basic import make_build_dir\n",
    "import os\n",
    "import onnx\n",
    "\n",
    "# Load model.\n",
    "file_path = str('../workspace/jh_fpga_amr/src/py/models')\n",
    "file_name = str('/vgglike_6f_6c_5re_5mp_pr0.3_quant8.onnx') # Change as needed.\n",
    "qonnx_model = onnx.load(file_path + file_name)\n",
    "showInNetron(file_path + file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5962fa99-0100-4162-96e0-d707434cb08e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stopping http://0.0.0.0:8081\n",
      "Serving '../workspace/jh_fpga_amr/src/py/models/cleanup/vgglike_6f_6c_5re_5mp_pr0.3_quant8.onnx' at http://0.0.0.0:8081\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"400\"\n",
       "            src=\"http://localhost:8081/\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "            \n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x7fdd6dc1ead0>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from qonnx.util.cleanup import cleanup\n",
    "\n",
    "# Run QONNX cleanup.\n",
    "os.makedirs(os.path.dirname(file_path + '/cleanup' + file_name), exist_ok=True)\n",
    "export_onnx_path_cleaned = file_path + '/cleanup' + file_name\n",
    "cleanup(file_path + file_name, out_file=export_onnx_path_cleaned)\n",
    "showInNetron(export_onnx_path_cleaned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6f4dee4b-bf52-412a-9092-92deed760dc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stopping http://0.0.0.0:8081\n",
      "Serving '../workspace/jh_fpga_amr/src/py/models/conv/vgglike_6f_6c_5re_5mp_pr0.3_quant8.onnx' at http://0.0.0.0:8081\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"400\"\n",
       "            src=\"http://localhost:8081/\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "            \n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x7fdd6dc1ed40>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from finn.transformation.qonnx.convert_qonnx_to_finn import ConvertQONNXtoFINN\n",
    "from qonnx.core.modelwrapper import ModelWrapper\n",
    "\n",
    "# Load model using ModelWrapper and convert to FINN format from QONNX.\n",
    "model = ModelWrapper(export_onnx_path_cleaned)\n",
    "model = model.transform(ConvertQONNXtoFINN())\n",
    "\n",
    "export_onnx_path_converted = file_path + '/conv' + file_name\n",
    "os.makedirs(os.path.dirname(export_onnx_path_converted), exist_ok=True)\n",
    "model.save(export_onnx_path_converted)\n",
    "showInNetron(export_onnx_path_converted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ed4646fe-0e39-4faf-97b9-5ad8735abacf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#from qonnx.transformation.general import GiveReadableTensorNames, GiveUniqueNodeNames, RemoveStaticGraphInputs\n",
    "#from qonnx.transformation.infer_shapes import InferShapes\n",
    "#from qonnx.transformation.infer_datatypes import InferDataTypes\n",
    "#from qonnx.transformation.fold_constants import FoldConstants\n",
    "#from qonnx.transformation.change_3d_tensors_to_4d import Change3DTo4DTensors\n",
    "#import finn.transformation.streamline.absorb as absorb\n",
    "#import finn.transformation.fpgadataflow.convert_to_hw_layers as to_hw\n",
    "#from finn.transformation.qonnx.convert_qonnx_to_finn import ConvertQONNXtoFINN\n",
    "#from finn.transformation.fpgadataflow.convert_to_hw_layers import InferChannelwiseLinearLayer, InferLabelSelectLayer, InferStreamingMaxPool\n",
    "#from finn.transformation.streamline import Streamline\n",
    "#from qonnx.transformation.lower_convs_to_matmul import LowerConvsToMatMul\n",
    "#from qonnx.transformation.bipolar_to_xnor import ConvertBipolarMatMulToXnorPopcount\n",
    "#import finn.transformation.streamline.absorb as absorb\n",
    "#from finn.transformation.streamline.reorder import MakeMaxPoolNHWC, MoveScalarLinearPastInvariants\n",
    "#from qonnx.transformation.infer_data_layouts import InferDataLayouts\n",
    "\n",
    "#from qonnx.transformation.base import Transformation\n",
    "#from finn.transformation.qonnx.qonnx_activation_handlers import QuantReluHandler\n",
    "\n",
    "#model = model.transform(InferShapes())\n",
    "#model = model.transform(FoldConstants())\n",
    "#model = model.transform(GiveUniqueNodeNames())\n",
    "#model = model.transform(InferChannelwiseLinearLayer())\n",
    "#model = model.transform(InferLabelSelectLayer())\n",
    "#model = model.transform(MoveScalarLinearPastInvariants())\n",
    "\n",
    "#model = model.transform(MakeMaxPoolNHWC())\n",
    "#model = model.transform(absorb.AbsorbConsecutiveTransposes())\n",
    "#model = model.transform(absorb.AbsorbTransposeIntoMultiThreshold())\n",
    "#model = model.transform(ConvertBipolarMatMulToXnorPopcount())\n",
    "#model = model.transform(Streamline())\n",
    "#model = model.transform(InferStreamingMaxPool())\n",
    "#model = model.transform(GiveReadableTensorNames())\n",
    "#model = model.transform(InferDataTypes())\n",
    "#model = model.transform(RemoveStaticGraphInputs())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8c856ac5-8724-4748-a457-e6d55480cbc8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stopping http://0.0.0.0:8081\n",
      "Serving '../workspace/jh_fpga_amr/src/py/models/verif/vgglike_6f_6c_5re_5mp_pr0.3_quant8.onnx' at http://0.0.0.0:8081\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"400\"\n",
       "            src=\"http://localhost:8081/\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "            \n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x7fdd6dc1ea70>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from finn.transformation.streamline import Streamline\n",
    "from qonnx.transformation.change_3d_tensors_to_4d import Change3DTo4DTensors\n",
    "from qonnx.transformation.lower_convs_to_matmul import LowerConvsToMatMul\n",
    "from qonnx.transformation.general import RemoveUnusedTensors, GiveUniqueNodeNames\n",
    "from finn.transformation.fpgadataflow.create_dataflow_partition import CreateDataflowPartition\n",
    "\n",
    "model = model.transform(Streamline()) # Only single model path supported.\n",
    "model = model.transform(Change3DTo4DTensors()) # Necessary, FINN doesn't like 1d.\n",
    "model = model.transform(LowerConvsToMatMul()) # Also necessary for build, need the 4D conversion first.\n",
    "#model = model.transform(absorb.AbsorbScalarMulAddIntoTopK())\n",
    "#model = model.transform(to_hw.InferChannelwiseLinearLayer())\n",
    "#model = model.transform(to_hw.InferLabelSelectLayer())\n",
    "model = model.transform(GiveUniqueNodeNames())\n",
    "model = model.transform(RemoveUnusedTensors())\n",
    "model = model.transform(CreateDataflowPartition())\n",
    "\n",
    "os.makedirs(os.path.dirname(file_path + '/verif' + file_name), exist_ok=True)\n",
    "verif_model_filename = file_path + '/verif' + file_name\n",
    "model.save(verif_model_filename)\n",
    "showInNetron(verif_model_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7a225114-8e31-4ec2-9096-bb5556a8a8bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Runs a resource estimate build.\n",
    "import finn.builder.build_dataflow as build\n",
    "import finn.builder.build_dataflow_config as build_cfg\n",
    "import os\n",
    "import shutil\n",
    "\n",
    "verif_model_filename = file_path + '/verif' + file_name\n",
    "model_file = verif_model_filename\n",
    "\n",
    "estimates_output_dir = file_path + '/output_estimates_new' + file_name\n",
    "\n",
    "# Delete previous run results if exist.\n",
    "if os.path.exists(estimates_output_dir):\n",
    "    shutil.rmtree(estimates_output_dir)\n",
    "    print(\"Previous run results deleted!\")\n",
    "\n",
    "\n",
    "cfg_estimates = build.DataflowBuildConfig(\n",
    "    output_dir          = estimates_output_dir,\n",
    "    mvau_wwidth_max     = 80,\n",
    "    target_fps          = 1000000,\n",
    "    synth_clk_period_ns = 10.0,\n",
    "    fpga_part           = \"xc7z020clg400-1\",\n",
    "    steps               = build_cfg.estimate_only_dataflow_steps,\n",
    "    generate_outputs=[\n",
    "        build_cfg.DataflowOutputType.ESTIMATE_REPORTS,\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "480a0199-5f66-46d1-81a5-d56980882cbc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building dataflow accelerator from ../workspace/jh_fpga_amr/src/py/models/verif/vgglike_6f_6c_5re_5mp_pr0.3_quant8.onnx\n",
      "Intermediate outputs will be generated in /tmp/finn_dev_rothej\n",
      "Final outputs will be generated in ../workspace/jh_fpga_amr/src/py/models/output_estimates_new/vgglike_6f_6c_5re_5mp_pr0.3_quant8.onnx\n",
      "Build log is at ../workspace/jh_fpga_amr/src/py/models/output_estimates_new/vgglike_6f_6c_5re_5mp_pr0.3_quant8.onnx/build_dataflow.log\n",
      "Running step: step_qonnx_to_finn [1/10]\n",
      "Running step: step_tidy_up [2/10]\n",
      "Running step: step_streamline [3/10]\n",
      "Running step: step_convert_to_hw [4/10]\n",
      "Running step: step_create_dataflow_partition [5/10]\n",
      "Running step: step_specialize_layers [6/10]\n",
      "Running step: step_target_fps_parallelization [7/10]\n",
      "Running step: step_apply_folding_config [8/10]\n",
      "Running step: step_minimize_bit_width [9/10]\n",
      "Running step: step_generate_estimate_reports [10/10]\n",
      "Completed successfully\n",
      "CPU times: user 4.46 s, sys: 651 ms, total: 5.11 s\n",
      "Wall time: 4.34 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "build.build_dataflow_cfg(model_file, cfg_estimates);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0a5967c7-9ded-4bb5-8dae-6b213a482154",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resource Utilization:\n",
      "BRAM_18K: 22.0\n",
      "LUT: 3580.0\n",
      "URAM: 0.0\n",
      "DSP: 24.0\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "json_file_path = estimates_output_dir + \"/report/estimate_layer_resources.json\"\n",
    "\n",
    "with open(json_file_path, 'r') as file:\n",
    "    data = json.load(file)\n",
    "\n",
    "total_resources = data['total']\n",
    "\n",
    "# Print utilization details.\n",
    "print(\"Resource Utilization:\")\n",
    "print(f\"BRAM_18K: {total_resources['BRAM_18K']}\")\n",
    "print(f\"LUT: {total_resources['LUT']}\")\n",
    "print(f\"URAM: {total_resources['URAM']}\")\n",
    "print(f\"DSP: {total_resources['DSP']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8d7578d6-2397-4616-bd1e-ccaa05ff2322",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Network Performance:\n",
      "critical_path_cycles: 260\n",
      "max_cycles: 98\n",
      "max_cycles_node_name: ConvolutionInputGenerator_rtl_0\n",
      "estimated_throughput_fps: 1020408.1632653062\n",
      "estimated_latency_ns: 2600.0\n"
     ]
    }
   ],
   "source": [
    "json_file_path = estimates_output_dir + \"/report/estimate_network_performance.json\"\n",
    "\n",
    "with open(json_file_path, 'r') as file:\n",
    "    data = json.load(file)\n",
    "\n",
    "# Print network performance estimates. Tends to over-estimate since it cannot capture the effects\n",
    "# of various synth optimizations.\n",
    "print(\"Network Performance:\")\n",
    "for key, value in data.items():\n",
    "    print(f\"{key}: {value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "84e67f03-413f-4d64-a374-701093c293a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer Cycles:\n",
      "FMPadding_rtl_0: 34\n",
      "ConvolutionInputGenerator_rtl_0: 98\n",
      "MVAU_rtl_0: 64\n",
      "Thresholding_rtl_0: 64\n"
     ]
    }
   ],
   "source": [
    "json_file_path = estimates_output_dir + \"/report/estimate_layer_cycles.json\"\n",
    "\n",
    "with open(json_file_path, 'r') as file:\n",
    "    data = json.load(file)\n",
    "\n",
    "# All layers are running in parallel, so slowest layer determines overall throughput.\n",
    "# FINN tries to parallelize each layer so that they all take a similar no. of cycles.\n",
    "# Summing up all layer cycle estimates will give the overall network latency.\n",
    "print(\"Layer Cycles:\")\n",
    "for key, value in data.items():\n",
    "    print(f\"{key}: {value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4f2c76b8-046e-47b5-9b2a-3a57a2ae11df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Previous run results deleted!\n"
     ]
    }
   ],
   "source": [
    "## Runs a synth build to view rtlsim performance. All pulled from 3-build-accelerator-with-finn.\n",
    "import finn.builder.build_dataflow as build\n",
    "import finn.builder.build_dataflow_config as build_cfg\n",
    "import os\n",
    "import shutil\n",
    "\n",
    "model_file = verif_model_filename\n",
    "\n",
    "rtlsim_output_dir = file_path + '/output_rtl' + file_name\n",
    "\n",
    "# Delete previous run results if exist.\n",
    "if os.path.exists(rtlsim_output_dir):\n",
    "    shutil.rmtree(rtlsim_output_dir)\n",
    "    print(\"Previous run results deleted!\")\n",
    "\n",
    "cfg_stitched_ip = build.DataflowBuildConfig(\n",
    "    output_dir          = rtlsim_output_dir,\n",
    "    mvau_wwidth_max     = 80,\n",
    "    target_fps          = 1000000,\n",
    "    synth_clk_period_ns = 10.0,\n",
    "    fpga_part           = \"xc7z020clg400-1\",\n",
    "    generate_outputs=[\n",
    "        build_cfg.DataflowOutputType.STITCHED_IP,\n",
    "        build_cfg.DataflowOutputType.RTLSIM_PERFORMANCE,\n",
    "        build_cfg.DataflowOutputType.OOC_SYNTH,\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "69c07d85-6e48-4a48-afcd-a663cc588e5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building dataflow accelerator from ../workspace/jh_fpga_amr/src/py/models/verif/vgglike_6f_6c_5re_5mp_pr0.3_quant8.onnx\n",
      "Intermediate outputs will be generated in /tmp/finn_dev_rothej\n",
      "Final outputs will be generated in ../workspace/jh_fpga_amr/src/py/models/output_rtl/vgglike_6f_6c_5re_5mp_pr0.3_quant8.onnx\n",
      "Build log is at ../workspace/jh_fpga_amr/src/py/models/output_rtl/vgglike_6f_6c_5re_5mp_pr0.3_quant8.onnx/build_dataflow.log\n",
      "Running step: step_qonnx_to_finn [1/19]\n",
      "Running step: step_tidy_up [2/19]\n",
      "Running step: step_streamline [3/19]\n",
      "Running step: step_convert_to_hw [4/19]\n",
      "Running step: step_create_dataflow_partition [5/19]\n",
      "Running step: step_specialize_layers [6/19]\n",
      "Running step: step_target_fps_parallelization [7/19]\n",
      "Running step: step_apply_folding_config [8/19]\n",
      "Running step: step_minimize_bit_width [9/19]\n",
      "Running step: step_generate_estimate_reports [10/19]\n",
      "Running step: step_hw_codegen [11/19]\n",
      "Running step: step_hw_ipgen [12/19]\n",
      "Running step: step_set_fifo_depths [13/19]\n",
      "Running step: step_create_stitched_ip [14/19]\n",
      "Running step: step_measure_rtlsim_performance [15/19]\n",
      "Running step: step_out_of_context_synthesis [16/19]\n",
      "Running step: step_synthesize_bitfile [17/19]\n",
      "Running step: step_make_pynq_driver [18/19]\n",
      "Running step: step_deployment_package [19/19]\n",
      "Completed successfully\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Note: This will take ~ 10 mins to complete, uses Vivado for build.\n",
    "#%%time\n",
    "build.build_dataflow_cfg(model_file, cfg_stitched_ip)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d2e4cc4e-9149-4061-8e09-ecf20cb4b048",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RTL Hardware Util:\n",
      "vivado_proj_folder: /tmp/finn_dev_rothej/synth_out_of_context_i65c8lvo/results_finn_design_wrapper\n",
      "LUT: 4471.0\n",
      "LUTRAM: 220.0\n",
      "FF: 9346.0\n",
      "DSP: 0.0\n",
      "BRAM: 35.0\n",
      "BRAM_18K: 48.0\n",
      "BRAM_36K: 11.0\n",
      "URAM: 0.0\n",
      "Carry: 590.0\n",
      "WNS: 0.466\n",
      "Delay: 0.466\n",
      "vivado_version: 2022.2\n",
      "vivado_build_no: 3671981.0\n",
      ": 0\n",
      "fmax_mhz: 104.88777008600796\n",
      "estimated_throughput_fps: 1070283.368224571\n"
     ]
    }
   ],
   "source": [
    "json_file_path = rtlsim_output_dir + \"/report/ooc_synth_and_timing.json\"\n",
    "\n",
    "with open(json_file_path, 'r') as file:\n",
    "    data = json.load(file)\n",
    "\n",
    "## Print hardware utilization estimates post-synthesis.\n",
    "# LUT - number of LUTs used.\n",
    "# LUTRAM - number of LUTs configured as RAM.\n",
    "# FF - number of FFs used.\n",
    "# DSP - number of DSP blocks used. Synth usually tries to conserve these when not needed because they are valuable.\n",
    "# BRAM - total block RAM tiles used.\n",
    "# Carry - carry chains used, used for arith. operations.\n",
    "# WNS - worst negative slack, positive value means timing is met.\n",
    "print(\"RTL Hardware Util:\")\n",
    "for key, value in data.items():\n",
    "    print(f\"{key}: {value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f9f3a2bd-4d5c-46d9-9bc9-b7aaa0e3c5fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RTL Performance Est:\n",
      "N_IN_TXNS: 32\n",
      "N_OUT_TXNS: 64\n",
      "cycles: 131\n",
      "N: 1\n",
      "latency_cycles: 131\n",
      "runtime[ms]: 0.0013100000000000002\n",
      "throughput[images/s]: 763358.7786259541\n",
      "fclk[mhz]: 100.0\n",
      "stable_throughput[images/s]: 763358.7786259541\n"
     ]
    }
   ],
   "source": [
    "json_file_path = rtlsim_output_dir + \"/report/rtlsim_performance.json\"\n",
    "\n",
    "with open(json_file_path, 'r') as file:\n",
    "    data = json.load(file)\n",
    "\n",
    "## Print performance estimates post-synthesis.\n",
    "# N_IN_TXNS - number of input transactions.\n",
    "# N_OUT_TXNS - number of output transactions.\n",
    "# cycles - total number of clk cycles for the process.\n",
    "# N - number of operations (batch size) handled in a single cycle.\n",
    "# latency_cycles - total cycle count.\n",
    "print(\"RTL Performance Est:\")\n",
    "for key, value in data.items():\n",
    "    print(f\"{key}: {value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "153d425a-ffb9-406f-9f97-52819d498e16",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
