{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e1aaeda6-652c-4bd2-9ace-d0b1ef7f6c62",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code in this notebook heavily pulled from https://github.com/Xilinx/finn/blob/main/notebooks/end2end_example/bnn-pynq/tfc_end2end_example.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2aeaa808-ec6c-4bdd-b6ab-893aeee655a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import finn\n",
    "from finn.util.visualization import showSrc, showInNetron\n",
    "from finn.util.basic import make_build_dir\n",
    "import os\n",
    "import onnx\n",
    "file_path = str('../workspace/jh_fpga_amr/src/py/models')\n",
    "file_name = str('/vgglike_5f_5c_4re_4mp_pr0_quant8.onnx')\n",
    "onnx_model = onnx.load(file_path + file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "415b5eba-d7a6-4898-bfd4-b8a4a1d7cdcc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Serving '../workspace/jh_fpga_amr/src/py/models/vgglike_5f_5c_4re_4mp_pr0_quant8.onnx' at http://0.0.0.0:8081\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"400\"\n",
       "            src=\"http://localhost:8081/\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "            \n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x7fe9ac39beb0>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from finn.util.visualization import showInNetron\n",
    "showInNetron(file_path + file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "17eec498-3339-4fdb-9c73-f1429e514ab2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from qonnx.core.modelwrapper import ModelWrapper\n",
    "from finn.transformation.qonnx.convert_qonnx_to_finn import ConvertQONNXtoFINN\n",
    "model = ModelWrapper(file_path + file_name)\n",
    "model = model.transform(ConvertQONNXtoFINN())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "470d48e7-d154-492c-844d-79718cc0bbb2",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index (1) out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 11\u001b[0m\n\u001b[1;32m      9\u001b[0m model \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mtransform(MoveScalarLinearPastInvariants())\n\u001b[1;32m     10\u001b[0m model \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mtransform(Streamline())\n\u001b[0;32m---> 11\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtransform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mLowerConvsToMatMul\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     12\u001b[0m model \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mtransform(MakeMaxPoolNHWC())\n\u001b[1;32m     13\u001b[0m model \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mtransform(absorb\u001b[38;5;241m.\u001b[39mAbsorbTransposeIntoMultiThreshold())\n",
      "File \u001b[0;32m/home/rothej/finn/deps/qonnx/src/qonnx/core/modelwrapper.py:140\u001b[0m, in \u001b[0;36mModelWrapper.transform\u001b[0;34m(self, transformation, make_deepcopy, cleanup)\u001b[0m\n\u001b[1;32m    138\u001b[0m model_was_changed \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    139\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m model_was_changed:\n\u001b[0;32m--> 140\u001b[0m     (transformed_model, model_was_changed) \u001b[38;5;241m=\u001b[39m \u001b[43mtransformation\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtransformed_model\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    141\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cleanup:\n\u001b[1;32m    142\u001b[0m     transformed_model\u001b[38;5;241m.\u001b[39mcleanup()\n",
      "File \u001b[0;32m/home/rothej/finn/deps/qonnx/src/qonnx/transformation/lower_convs_to_matmul.py:77\u001b[0m, in \u001b[0;36mLowerConvsToMatMul.apply\u001b[0;34m(self, model)\u001b[0m\n\u001b[1;32m     75\u001b[0m k \u001b[38;5;241m=\u001b[39m get_by_name(n\u001b[38;5;241m.\u001b[39mattribute, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mkernel_shape\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39mints\n\u001b[1;32m     76\u001b[0m k_h \u001b[38;5;241m=\u001b[39m k[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m---> 77\u001b[0m k_w \u001b[38;5;241m=\u001b[39m \u001b[43mk\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[1;32m     78\u001b[0m stride_h \u001b[38;5;241m=\u001b[39m get_by_name(n\u001b[38;5;241m.\u001b[39mattribute, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstrides\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39mints[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m     79\u001b[0m stride_w \u001b[38;5;241m=\u001b[39m get_by_name(n\u001b[38;5;241m.\u001b[39mattribute, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstrides\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39mints[\u001b[38;5;241m1\u001b[39m]\n",
      "\u001b[0;31mIndexError\u001b[0m: list index (1) out of range"
     ]
    }
   ],
   "source": [
    "from finn.transformation.streamline import Streamline\n",
    "from qonnx.transformation.lower_convs_to_matmul import LowerConvsToMatMul\n",
    "from qonnx.transformation.bipolar_to_xnor import ConvertBipolarMatMulToXnorPopcount\n",
    "import finn.transformation.streamline.absorb as absorb\n",
    "from finn.transformation.streamline.reorder import MakeMaxPoolNHWC, MoveScalarLinearPastInvariants\n",
    "from qonnx.transformation.infer_data_layouts import InferDataLayouts\n",
    "from qonnx.transformation.general import RemoveUnusedTensors\n",
    "\n",
    "model = model.transform(MoveScalarLinearPastInvariants())\n",
    "model = model.transform(Streamline())\n",
    "model = model.transform(LowerConvsToMatMul())\n",
    "model = model.transform(MakeMaxPoolNHWC())\n",
    "model = model.transform(absorb.AbsorbTransposeIntoMultiThreshold())\n",
    "model = model.transform(ConvertBipolarMatMulToXnorPopcount())\n",
    "model = model.transform(Streamline())\n",
    "# absorb final add-mul nodes into TopK\n",
    "model = model.transform(absorb.AbsorbScalarMulAddIntoTopK())\n",
    "model = model.transform(InferDataLayouts())\n",
    "model = model.transform(RemoveUnusedTensors())\n",
    "model.save(build_dir + \"/end2end_cnv_w1a1_streamlined.onnx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "aeeb3a6c-968b-4749-b6e9-6c1f2e71f3cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    def analysis(self, analysis_fxn):\n",
      "        \"\"\"Runs given anaylsis_fxn on this model and return resulting dict.\"\"\"\n",
      "        return analysis_fxn(self)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from qonnx.core.modelwrapper import ModelWrapper\n",
    "from finn.util.visualization import showSrc\n",
    "\n",
    "model = ModelWrapper(onnx_model)\n",
    "showSrc(ModelWrapper.analysis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0b1d2701-9503-4ccd-a6b4-e8b8b14a0cb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stopping http://0.0.0.0:8081\n",
      "Serving '../workspace/jh_fpga_amr/src/py/models/conv/vgglike_5f_5c_4re_4mp_pr0_quant8.onnx' at http://0.0.0.0:8081\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"400\"\n",
       "            src=\"http://localhost:8081/\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "            \n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x7fe4f8c25630>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.makedirs(os.path.dirname(file_path+'/conv'+file_name), exist_ok=True)\n",
    "model.save(file_path+'/conv'+file_name)\n",
    "showInNetron(file_path+'/conv'+file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d676954a-f933-419c-bbe8-5325be37c6af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stopping http://0.0.0.0:8081\n",
      "Serving '../workspace/jh_fpga_amr/src/py/models/transform/vgglike_5f_5c_4re_4mp_pr0_quant8.onnx' at http://0.0.0.0:8081\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"400\"\n",
       "            src=\"http://localhost:8081/\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "            \n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x7fe502653220>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Tidy up transformations.\n",
    "from qonnx.transformation.general import GiveReadableTensorNames, GiveUniqueNodeNames, RemoveStaticGraphInputs\n",
    "from qonnx.transformation.infer_shapes import InferShapes\n",
    "from qonnx.transformation.infer_datatypes import InferDataTypes\n",
    "from qonnx.transformation.fold_constants import FoldConstants\n",
    "\n",
    "model = model.transform(InferShapes())\n",
    "model = model.transform(FoldConstants())\n",
    "model = model.transform(GiveUniqueNodeNames())\n",
    "model = model.transform(GiveReadableTensorNames())\n",
    "model = model.transform(InferDataTypes())\n",
    "model = model.transform(RemoveStaticGraphInputs())\n",
    "\n",
    "os.makedirs(os.path.dirname(file_path+'/transform'+file_name), exist_ok=True)\n",
    "model.save(file_path+'/transform'+file_name)\n",
    "showInNetron(file_path+'/transform'+file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0bd2b96d-a1b0-4f43-8a81-49477a4bcd4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stopping http://0.0.0.0:8081\n",
      "Serving '../workspace/jh_fpga_amr/src/py/models/hw_layers/vgglike_5f_5c_4re_4mp_pr0_quant8.onnx' at http://0.0.0.0:8081\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"400\"\n",
       "            src=\"http://localhost:8081/\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "            \n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x7fe4f8c25750>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Preparing to convert to hardware layers.\n",
    "import finn.transformation.fpgadataflow.convert_to_hw_layers as to_hw\n",
    "\n",
    "model = ModelWrapper(file_path+'/transform'+file_name)\n",
    "model = model.transform(to_hw.InferBinaryMatrixVectorActivation())\n",
    "# TopK to LabelSelect.\n",
    "model = model.transform(to_hw.InferLabelSelectLayer())\n",
    "# Input quantization (if any) to standalone thresholding.\n",
    "model = model.transform(to_hw.InferThresholdingLayer())\n",
    "\n",
    "os.makedirs(os.path.dirname(file_path+'/hw_layers'+file_name), exist_ok=True)\n",
    "model.save(file_path+'/hw_layers'+file_name)\n",
    "showInNetron(file_path+'/hw_layers'+file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "df11eb19-41e2-44cb-a138-f0a3b4d8f9b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stopping http://0.0.0.0:8081\n",
      "Serving '../workspace/jh_fpga_amr/src/py/models/dataflow_parent/vgglike_5f_5c_4re_4mp_pr0_quant8.onnx' at http://0.0.0.0:8081\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"400\"\n",
       "            src=\"http://localhost:8081/\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "            \n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x7fe50269d1e0>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Separating HLS layers into another model.\n",
    "from finn.transformation.fpgadataflow.create_dataflow_partition import CreateDataflowPartition\n",
    "\n",
    "parent_model = model.transform(CreateDataflowPartition())\n",
    "os.makedirs(os.path.dirname(file_path+'/dataflow_parent'+file_name), exist_ok=True)\n",
    "parent_model.save(file_path+'/dataflow_parent'+file_name)\n",
    "showInNetron(file_path+'/dataflow_parent'+file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d0376033-690e-4269-b95d-f5c93ebc3971",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change this if you have a different PYNQ board, see list above.\n",
    "from finn.util.basic import pynq_part_map\n",
    "pynq_board = \"Pynq-Z1\"\n",
    "fpga_part = pynq_part_map[pynq_board]\n",
    "target_clk_ns = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "15f6ec06-cdea-45a0-992e-5e28455515e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stopping http://0.0.0.0:8081\n",
      "Serving '../workspace/jh_fpga_amr/src/py/models/specialize_layers_hls/vgglike_5f_5c_4re_4mp_pr0_quant8.onnx' at http://0.0.0.0:8081\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"400\"\n",
       "            src=\"http://localhost:8081/\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "            \n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x7fe4f8c27850>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Each abstaction layer converted to HLS variant.\n",
    "from finn.transformation.fpgadataflow.specialize_layers import SpecializeLayers\n",
    "model = model.transform(SpecializeLayers(fpga_part))\n",
    "\n",
    "os.makedirs(os.path.dirname(file_path+'/specialize_layers_hls'+file_name), exist_ok=True)\n",
    "model.save(file_path+'/specialize_layers_hls'+file_name)\n",
    "showInNetron(file_path+'/specialize_layers_hls'+file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7c673550-28f0-4c5f-b07b-cafcfffbf535",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stopping http://0.0.0.0:8081\n",
      "Serving '../workspace/jh_fpga_amr/src/py/models/set_folding_factors/vgglike_5f_5c_4re_4mp_pr0_quant8.onnx' at http://0.0.0.0:8081\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"400\"\n",
       "            src=\"http://localhost:8081/\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "            \n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x7fe502652c50>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Hoping to not have to use this at all.\n",
    "## In this notebook we are setting the folding factors and FIFO depths manually but it is possible to use FINN transformations for this (SetFolding and InsertAndSetFIFODepths).\n",
    "\n",
    "#fc_layers = model.get_nodes_by_op_type(\"MVAU_hls\")\n",
    "## (PE, SIMD, in_fifo_depth, out_fifo_depth, ramstyle) for each layer\n",
    "#config = [\n",
    "#    (16, 49, [16], [64], \"block\"),\n",
    "#    (8, 8, [64], [64], \"auto\"),\n",
    "#    (8, 8, [64], [64], \"auto\"),\n",
    "#    (10, 8, [64], [10], \"distributed\"),\n",
    "#]\n",
    "#for fcl, (pe, simd, ififo, ofifo, ramstyle) in zip(fc_layers, config):\n",
    "#    fcl_inst = getCustomOp(fcl)\n",
    "#    fcl_inst.set_nodeattr(\"PE\", pe)\n",
    "#    fcl_inst.set_nodeattr(\"SIMD\", simd)\n",
    "#    fcl_inst.set_nodeattr(\"inFIFODepths\", ififo)\n",
    "#    fcl_inst.set_nodeattr(\"outFIFODepths\", ofifo)\n",
    "#    fcl_inst.set_nodeattr(\"ram_style\", ramstyle)\n",
    "    \n",
    "## Set parallelism for input quantizer to be same as first layer's SIMD.\n",
    "#inp_qnt_node = model.get_nodes_by_op_type(\"Thresholding_hls\")[0]\n",
    "#inp_qnt = getCustomOp(inp_qnt_node)\n",
    "#inp_qnt.set_nodeattr(\"PE\", 49)\n",
    "\n",
    "os.makedirs(os.path.dirname(file_path+'/set_folding_factors'+file_name), exist_ok=True)\n",
    "model.save(file_path+'/set_folding_factors'+file_name)\n",
    "showInNetron(file_path+'/set_folding_factors'+file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e2d99247-171b-4a7a-98d7-2b881f05792d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ModelWrapper(file_path+'/set_folding_factors'+file_name)\n",
    "model = model.transform(GiveUniqueNodeNames())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ae0fbe2d-e60a-4185-b841-0ccec958da31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{}\n"
     ]
    }
   ],
   "source": [
    "from finn.analysis.fpgadataflow.hls_synth_res_estimation import hls_synth_res_estimation\n",
    "resource_estimates = hls_synth_res_estimation(model)\n",
    "print(resource_estimates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bc4b1473-ca30-445e-8ada-e572b43a2eee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Previous run results deleted!\n"
     ]
    }
   ],
   "source": [
    "## Default builder flow for resource estimations. From advanced_builder_settings tutorial.\n",
    "import finn.builder.build_dataflow as build\n",
    "import finn.builder.build_dataflow_config as build_cfg\n",
    "import os\n",
    "import shutil\n",
    "\n",
    "estimates_output_dir = file_path+\"/output_estimates_only\"\n",
    "\n",
    "# Delete previous run results if exist.\n",
    "if os.path.exists(estimates_output_dir):\n",
    "    shutil.rmtree(estimates_output_dir)\n",
    "    print(\"Previous run results deleted!\")\n",
    "\n",
    "cfg_estimates = build.DataflowBuildConfig(\n",
    "    output_dir          = estimates_output_dir,\n",
    "    mvau_wwidth_max     = 80,\n",
    "    target_fps          = 10000,\n",
    "    synth_clk_period_ns = 10.0,\n",
    "    fpga_part           = \"xc7z020clg400-1\",\n",
    "    steps               = build_cfg.estimate_only_dataflow_steps,\n",
    "    generate_outputs=[\n",
    "        build_cfg.DataflowOutputType.ESTIMATE_REPORTS,\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1397a567-d8d0-4810-92d3-e2faf31de7ac",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "can only concatenate str (not \"ModelProto\") to str",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "File \u001b[0;32m<timed eval>:1\u001b[0m\n",
      "File \u001b[0;32m/home/rothej/finn/src/finn/builder/build_dataflow.py:113\u001b[0m, in \u001b[0;36mbuild_dataflow_cfg\u001b[0;34m(model_filename, cfg)\u001b[0m\n\u001b[1;32m    111\u001b[0m \u001b[38;5;66;03m# if start_step is specified, override the input model\u001b[39;00m\n\u001b[1;32m    112\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cfg\u001b[38;5;241m.\u001b[39mstart_step \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 113\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mBuilding dataflow accelerator from \u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mmodel_filename\u001b[49m)\n\u001b[1;32m    114\u001b[0m     model \u001b[38;5;241m=\u001b[39m ModelWrapper(model_filename)\n\u001b[1;32m    115\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[0;31mTypeError\u001b[0m: can only concatenate str (not \"ModelProto\") to str"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "build.build_dataflow_cfg(onnx_model, cfg_estimates);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9825a06c-14a9-4ede-9668-d87f67d917aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Synthesizing into Vitis - will take a while.\n",
    "from finn.transformation.fpgadataflow.make_zynq_proj import ZynqBuild\n",
    "model = ModelWrapper(file_path+'/set_folding_factors'+file_name)\n",
    "model = model.transform(ZynqBuild(platform = pynq_board, period_ns = target_clk_ns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23dc066a-93c4-4045-a094-777e9f35fe98",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Generate PYNQ driver from accelerator.\n",
    "from finn.transformation.fpgadataflow.make_pynq_driver import MakePYNQDriver\n",
    "model = model.transform(MakePYNQDriver(\"zynq-iodma\"))\n",
    "model.save(build_dir+'/post_synthesis'+file_name)\n",
    "showInNetron(build_dir+'/post_synthesis'+file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaa1ccfe-284d-4ba3-9393-3f54b4bfbfcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ModelWrapper(build_dir+'/post_synthesis'+file_name)\n",
    "sdp_node_middle = getCustomOp(model.graph.node[1])\n",
    "postsynth_layers = sdp_node_middle.get_nodeattr(\"model\")\n",
    "showInNetron(postsynth_layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44ebd875-edad-41ee-a89d-261b5ce11261",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ModelWrapper(postsynth_layers)\n",
    "model.model.metadata_props"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "834c2b76-92e5-4449-992d-f9f1da1af96b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ModelWrapper(build_dir+'/post_synthesis'+file_name)\n",
    "model.model.metadata_props"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bee1afc-bff9-4c75-b565-63599ae8d056",
   "metadata": {},
   "outputs": [],
   "source": [
    "! ls {model.get_metadata_prop(\"vivado_pynq_proj\")} # Directory of synthesized project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e70de490-cf87-42d0-8e11-c8aaa44d6938",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f5975b7-abce-4406-87f5-b5db0528a8fa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e73f353-ee88-4600-a304-606b00d4f0fa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
