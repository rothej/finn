{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5d5fc42e-1e7a-4649-bbfe-b660254925bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stopping http://0.0.0.0:8081\n",
      "Serving '../workspace/jh_fpga_amr/src/py/models/vgglike_5f_5c_4re_4mp_pr0_quant8.onnx' at http://0.0.0.0:8081\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"400\"\n",
       "            src=\"http://localhost:8081/\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "            \n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x7f4bfc1ab280>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import finn\n",
    "from finn.util.visualization import showSrc, showInNetron\n",
    "from finn.util.basic import make_build_dir\n",
    "import os\n",
    "import onnx\n",
    "file_path = str('../workspace/jh_fpga_amr/src/py/models')\n",
    "file_name = str('/vgglike_5f_5c_4re_4mp_pr0_quant8.onnx')\n",
    "onnx_model = onnx.load(file_path + file_name)\n",
    "showInNetron(file_path + file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5962fa99-0100-4162-96e0-d707434cb08e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stopping http://0.0.0.0:8081\n",
      "Serving '../workspace/jh_fpga_amr/src/py/models/cleanup/vgglike_5f_5c_4re_4mp_pr0_quant8.onnx' at http://0.0.0.0:8081\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"400\"\n",
       "            src=\"http://localhost:8081/\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "            \n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x7f4afcb0d810>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from qonnx.util.cleanup import cleanup_model\n",
    "from qonnx.core.modelwrapper import ModelWrapper\n",
    "import os\n",
    "os.makedirs(os.path.dirname(file_path + '/cleanup' + file_name), exist_ok=True)\n",
    "export_onnx_path_cleaned = file_path + '/cleanup' + file_name\n",
    "model = ModelWrapper(export_onnx_path_cleaned)\n",
    "model = cleanup_model(model)\n",
    "model.save(export_onnx_path_cleaned)\n",
    "showInNetron(export_onnx_path_cleaned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6f4dee4b-bf52-412a-9092-92deed760dc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input tensor name: global_in\n",
      "Output tensor name: global_out\n",
      "Input tensor shape: [1, 2, 32]\n",
      "Output tensor shape: [1, 9]\n",
      "Input tensor datatype: FLOAT32\n",
      "Output tensor datatype: FLOAT32\n",
      "List of node operator types in the graph: \n",
      "['Quant', 'Quant', 'Quant', 'Quant', 'Quant', 'Quant', 'Quant', 'Quant', 'Quant', 'Quant', 'Quant', 'Conv', 'Relu', 'MaxPool', 'Conv', 'Relu', 'MaxPool', 'Conv', 'Relu', 'MaxPool', 'Conv', 'Relu', 'MaxPool', 'Conv', 'Relu', 'Reshape', 'Gemm', 'Relu', 'Gemm', 'Relu', 'Gemm', 'Relu', 'Gemm', 'Relu', 'Gemm', 'Relu', 'Quant']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rothej/finn/deps/qonnx/src/qonnx/transformation/gemm_to_matmul.py:57: UserWarning: The GemmToMatMul transformation only offers explicit support for version 9 of the Gemm node, but the ONNX version of the supplied model is 11. Thus the transformation may fail or return incomplete results.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stopping http://0.0.0.0:8081\n",
      "Serving '../workspace/jh_fpga_amr/src/py/models/conv/vgglike_5f_5c_4re_4mp_pr0_quant8.onnx' at http://0.0.0.0:8081\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"400\"\n",
       "            src=\"http://localhost:8081/\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "            \n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x7f4afcb0dab0>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from finn.transformation.qonnx.convert_qonnx_to_finn import ConvertQONNXtoFINN\n",
    "from qonnx.core.modelwrapper import ModelWrapper\n",
    "model_for_sim = ModelWrapper(export_onnx_path_cleaned)\n",
    "\n",
    "from qonnx.core.datatype import DataType\n",
    "\n",
    "finnonnx_in_tensor_name = model_for_sim.graph.input[0].name\n",
    "finnonnx_out_tensor_name = model_for_sim.graph.output[0].name\n",
    "print(\"Input tensor name: %s\" % finnonnx_in_tensor_name)\n",
    "print(\"Output tensor name: %s\" % finnonnx_out_tensor_name)\n",
    "finnonnx_model_in_shape = model_for_sim.get_tensor_shape(finnonnx_in_tensor_name)\n",
    "finnonnx_model_out_shape = model_for_sim.get_tensor_shape(finnonnx_out_tensor_name)\n",
    "print(\"Input tensor shape: %s\" % str(finnonnx_model_in_shape))\n",
    "print(\"Output tensor shape: %s\" % str(finnonnx_model_out_shape))\n",
    "finnonnx_model_in_dt = model_for_sim.get_tensor_datatype(finnonnx_in_tensor_name)\n",
    "finnonnx_model_out_dt = model_for_sim.get_tensor_datatype(finnonnx_out_tensor_name)\n",
    "print(\"Input tensor datatype: %s\" % str(finnonnx_model_in_dt.name))\n",
    "print(\"Output tensor datatype: %s\" % str(finnonnx_model_out_dt.name))\n",
    "print(\"List of node operator types in the graph: \")\n",
    "print([x.op_type for x in model_for_sim.graph.node])\n",
    "\n",
    "model = model_for_sim.transform(ConvertQONNXtoFINN())\n",
    "\n",
    "export_onnx_path_converted = file_path + '/conv' + file_name\n",
    "os.makedirs(os.path.dirname(export_onnx_path_converted), exist_ok=True)\n",
    "model.save(export_onnx_path_converted)\n",
    "showInNetron(export_onnx_path_converted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ed4646fe-0e39-4faf-97b9-5ad8735abacf",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'QuantReluHandler' object has no attribute 'transform'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[15], line 27\u001b[0m\n\u001b[1;32m     25\u001b[0m model \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mtransform(InferDataTypes())\n\u001b[1;32m     26\u001b[0m model \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mtransform(RemoveStaticGraphInputs())\n\u001b[0;32m---> 27\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtransform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mApplyQuantReluHandler\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     28\u001b[0m model \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mtransform(Change3DTo4DTensors())\n\u001b[1;32m     29\u001b[0m model \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mtransform(absorb\u001b[38;5;241m.\u001b[39mAbsorbScalarMulAddIntoTopK())\n",
      "File \u001b[0;32m/home/rothej/finn/deps/qonnx/src/qonnx/core/modelwrapper.py:140\u001b[0m, in \u001b[0;36mModelWrapper.transform\u001b[0;34m(self, transformation, make_deepcopy, cleanup)\u001b[0m\n\u001b[1;32m    138\u001b[0m model_was_changed \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    139\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m model_was_changed:\n\u001b[0;32m--> 140\u001b[0m     (transformed_model, model_was_changed) \u001b[38;5;241m=\u001b[39m \u001b[43mtransformation\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtransformed_model\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    141\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cleanup:\n\u001b[1;32m    142\u001b[0m     transformed_model\u001b[38;5;241m.\u001b[39mcleanup()\n",
      "Cell \u001b[0;32mIn[15], line 17\u001b[0m, in \u001b[0;36mApplyQuantReluHandler.apply\u001b[0;34m(self, model)\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m node_index, node \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(model\u001b[38;5;241m.\u001b[39mgraph\u001b[38;5;241m.\u001b[39mnode):\n\u001b[1;32m     16\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m node\u001b[38;5;241m.\u001b[39mop_type \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRelu\u001b[39m\u001b[38;5;124m\"\u001b[39m: \n\u001b[0;32m---> 17\u001b[0m         \u001b[43mQuantReluHandler\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnode_index\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtransform\u001b[49m(model)\n\u001b[1;32m     18\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDebug\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m (model, \u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'QuantReluHandler' object has no attribute 'transform'"
     ]
    }
   ],
   "source": [
    "from qonnx.transformation.general import GiveReadableTensorNames, GiveUniqueNodeNames, RemoveStaticGraphInputs\n",
    "from qonnx.transformation.infer_shapes import InferShapes\n",
    "from qonnx.transformation.infer_datatypes import InferDataTypes\n",
    "from qonnx.transformation.fold_constants import FoldConstants\n",
    "from qonnx.transformation.change_3d_tensors_to_4d import Change3DTo4DTensors # New(ish) custom build op to handle Quant1D layers.\n",
    "import finn.transformation.streamline.absorb as absorb\n",
    "import finn.transformation.fpgadataflow.convert_to_hw_layers as to_hw\n",
    "from finn.transformation.qonnx.qonnx_activation_handlers import QuantReluHandler\n",
    "\n",
    "from qonnx.transformation.base import Transformation\n",
    "\n",
    "class ApplyQuantReluHandler(Transformation):\n",
    "    \"\"\" Custom transformation wrapper for the QuantReluHandler. \"\"\"\n",
    "    def apply(self, model):\n",
    "        for node_index, node in enumerate(model.graph.node):\n",
    "            if node.op_type == \"Relu\": \n",
    "                QuantReluHandler(model, node, node_index).transform(model)\n",
    "                print(\"Debug\")\n",
    "        return (model, False)\n",
    "\n",
    "model = model.transform(InferShapes())\n",
    "model = model.transform(FoldConstants())\n",
    "model = model.transform(GiveUniqueNodeNames())\n",
    "model = model.transform(GiveReadableTensorNames())\n",
    "model = model.transform(InferDataTypes())\n",
    "model = model.transform(RemoveStaticGraphInputs())\n",
    "model = model.transform(ApplyQuantReluHandler())\n",
    "model = model.transform(Change3DTo4DTensors())\n",
    "model = model.transform(absorb.AbsorbScalarMulAddIntoTopK())\n",
    "model = model.transform(to_hw.InferChannelwiseLinearLayer())\n",
    "model = model.transform(to_hw.InferLabelSelectLayer())\n",
    "model = model.transform(GiveUniqueNodeNames())\n",
    "\n",
    "os.makedirs(os.path.dirname(file_path + '/verif' + file_name), exist_ok=True)\n",
    "verif_model_filename = file_path + '/verif' + file_name\n",
    "model.save(verif_model_filename)\n",
    "showInNetron(verif_model_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7a225114-8e31-4ec2-9096-bb5556a8a8bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Previous run results deleted!\n"
     ]
    }
   ],
   "source": [
    "import finn.builder.build_dataflow as build\n",
    "import finn.builder.build_dataflow_config as build_cfg\n",
    "import os\n",
    "import shutil\n",
    "\n",
    "model_file = verif_model_filename\n",
    "\n",
    "estimates_output_dir = \"output_estimates_only\"\n",
    "\n",
    "# Delete previous run results if exist.\n",
    "if os.path.exists(estimates_output_dir):\n",
    "    shutil.rmtree(estimates_output_dir)\n",
    "    print(\"Previous run results deleted!\")\n",
    "\n",
    "\n",
    "cfg_estimates = build.DataflowBuildConfig(\n",
    "    output_dir          = estimates_output_dir,\n",
    "    mvau_wwidth_max     = 80,\n",
    "    target_fps          = 1000000,\n",
    "    synth_clk_period_ns = 10.0,\n",
    "    fpga_part           = \"xc7z020clg400-1\",\n",
    "    steps               = build_cfg.estimate_only_dataflow_steps,\n",
    "    generate_outputs=[\n",
    "        build_cfg.DataflowOutputType.ESTIMATE_REPORTS,\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "480a0199-5f66-46d1-81a5-d56980882cbc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building dataflow accelerator from ../workspace/jh_fpga_amr/src/py/models/verif/vgglike_5f_5c_4re_4mp_pr0_quant8.onnx\n",
      "Intermediate outputs will be generated in /tmp/finn_dev_rothej\n",
      "Final outputs will be generated in output_estimates_only\n",
      "Build log is at output_estimates_only/build_dataflow.log\n",
      "Running step: step_qonnx_to_finn [1/10]\n",
      "Running step: step_tidy_up [2/10]\n",
      "Running step: step_streamline [3/10]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/home/rothej/finn/src/finn/builder/build_dataflow.py\", line 158, in build_dataflow_cfg\n",
      "    model = transform_step(model, cfg)\n",
      "  File \"/home/rothej/finn/src/finn/builder/build_dataflow_steps.py\", line 317, in step_streamline\n",
      "    model = model.transform(LowerConvsToMatMul())\n",
      "  File \"/home/rothej/finn/deps/qonnx/src/qonnx/core/modelwrapper.py\", line 140, in transform\n",
      "    (transformed_model, model_was_changed) = transformation.apply(transformed_model)\n",
      "  File \"/home/rothej/finn/deps/qonnx/src/qonnx/transformation/lower_convs_to_matmul.py\", line 77, in apply\n",
      "    k_w = k[1]\n",
      "IndexError: list index (1) out of range\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> \u001b[0;32m/home/rothej/finn/deps/qonnx/src/qonnx/transformation/lower_convs_to_matmul.py\u001b[0m(77)\u001b[0;36mapply\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m     75 \u001b[0;31m                \u001b[0mk\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_by_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mattribute\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"kernel_shape\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mints\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     76 \u001b[0;31m                \u001b[0mk_h\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m---> 77 \u001b[0;31m                \u001b[0mk_w\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     78 \u001b[0;31m                \u001b[0mstride_h\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_by_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mattribute\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"strides\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mints\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     79 \u001b[0;31m                \u001b[0mstride_w\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_by_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mattribute\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"strides\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mints\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n",
      "--KeyboardInterrupt--\n",
      "\n",
      "KeyboardInterrupt: Interrupted by user\n",
      "Build failed\n",
      "CPU times: user 2.88 s, sys: 408 ms, total: 3.29 s\n",
      "Wall time: 2min 20s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "build.build_dataflow_cfg(model_file, cfg_estimates);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0a5967c7-9ded-4bb5-8dae-6b213a482154",
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mexists(estimates_output_dir \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/report/estimate_layer_resources.json\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "assert os.path.exists(estimates_output_dir + \"/report/estimate_layer_resources.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d7578d6-2397-4616-bd1e-ccaa05ff2322",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f2c76b8-046e-47b5-9b2a-3a57a2ae11df",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
